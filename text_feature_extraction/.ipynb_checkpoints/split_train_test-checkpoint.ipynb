{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from random import sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_ratio=0.2\n",
    "path_to_preprocessed_texts = os.path.join(os.getcwd(),\n",
    "                                          'texts','preprocessed_texts_for_doc2vec.pkl')\n",
    "\n",
    "df_preprocessed_texts = pd.read_pickle(path_to_preprocessed_texts)\n",
    "\n",
    "preprocessed_texts = df_preprocessed_texts.preprocessed_texts.values.tolist()\n",
    "labels = df_preprocessed_texts['labels'].values.tolist()\n",
    "\n",
    "unique_labels=sorted(set(labels))\n",
    "number_categories=len(unique_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10, 7, 8, 19, 18, 26, 48, 40, 45, 56, 60, 62, 71, 81, 95, 96, 102, 109, 124, 127, 133, 131, 147, 154, 151, 162, 165, 171, 177, 183, 190, 199, 200, 207, 215, 225, 231, 235, 252, 249, 243, 258, 274, 281, 280, 282, 289, 291, 304, 296, 307, 314]\n",
      "[0, 5, 4, 23, 20, 27, 42, 34, 47, 54, 51, 67, 71, 84, 99, 101, 108, 103, 127, 124, 135, 136, 140, 159, 156, 160, 169, 181, 180, 174, 187, 195, 205, 208, 217, 223, 240, 237, 262, 256, 253, 258, 273, 283, 266, 279, 294, 290, 300, 301, 306, 307]\n",
      "[6, 10, 5, 17, 19, 28, 44, 45, 35, 54, 53, 65, 72, 84, 97, 90, 113, 112, 119, 120, 136, 129, 139, 150, 155, 160, 168, 185, 179, 173, 190, 203, 198, 206, 214, 224, 238, 232, 242, 256, 262, 241, 278, 270, 273, 277, 286, 295, 304, 300, 309, 312]\n",
      "[12, 8, 5, 16, 23, 29, 41, 36, 44, 56, 53, 65, 78, 87, 98, 93, 107, 112, 126, 123, 135, 132, 140, 155, 152, 164, 160, 182, 173, 174, 188, 199, 201, 211, 219, 228, 237, 235, 262, 255, 245, 244, 283, 267, 274, 276, 286, 292, 299, 304, 313, 308]\n",
      "[10, 9, 12, 23, 16, 32, 36, 35, 37, 54, 51, 65, 77, 80, 91, 94, 113, 110, 123, 122, 132, 133, 140, 155, 159, 165, 170, 179, 185, 174, 193, 198, 203, 209, 221, 230, 240, 231, 255, 257, 260, 241, 283, 280, 272, 274, 286, 289, 303, 296, 315, 311]\n",
      "[7, 8, 0, 24, 25, 27, 48, 39, 49, 55, 59, 68, 72, 85, 98, 97, 105, 107, 118, 128, 138, 129, 147, 158, 156, 162, 168, 185, 172, 183, 187, 197, 205, 206, 214, 230, 234, 231, 260, 243, 249, 250, 285, 280, 269, 277, 288, 292, 300, 305, 308, 311]\n",
      "[10, 1, 2, 21, 23, 26, 36, 43, 48, 60, 57, 65, 75, 79, 92, 93, 114, 106, 128, 120, 131, 129, 140, 149, 159, 169, 163, 173, 172, 182, 192, 198, 205, 211, 220, 228, 236, 238, 262, 243, 261, 246, 280, 270, 265, 264, 292, 286, 296, 298, 309, 315]\n",
      "[14, 10, 2, 15, 17, 33, 34, 45, 46, 53, 58, 63, 72, 79, 99, 98, 108, 110, 123, 122, 130, 134, 141, 158, 157, 161, 170, 177, 183, 184, 192, 200, 199, 209, 219, 225, 232, 235, 247, 253, 256, 254, 279, 285, 272, 278, 288, 291, 300, 303, 310, 309]\n",
      "[7, 12, 1, 18, 25, 31, 44, 38, 49, 52, 60, 69, 71, 82, 101, 92, 112, 102, 124, 119, 134, 130, 139, 151, 152, 161, 160, 174, 183, 172, 188, 194, 196, 213, 220, 228, 239, 236, 255, 247, 252, 244, 279, 272, 281, 265, 289, 290, 297, 303, 310, 311]\n",
      "[8, 0, 4, 22, 20, 28, 47, 39, 38, 60, 54, 67, 73, 85, 99, 93, 105, 111, 125, 123, 138, 133, 147, 152, 157, 166, 163, 172, 182, 177, 190, 197, 202, 210, 217, 229, 233, 239, 244, 242, 256, 246, 284, 267, 274, 277, 293, 287, 302, 303, 313, 315]\n"
     ]
    }
   ],
   "source": [
    "for number_of_iteration in range(1,11): # 10 crossvalidation runs\n",
    "    path_test_data = os.path.join(os.getcwd(),'models','test',str(number_of_iteration),'recipes_test_dataset.pkl')\n",
    "    path_train_data = os.path.join(os.getcwd(),'models','train',str(number_of_iteration), 'recipes_train_dataset.pkl')\n",
    "\n",
    "    index_test=[]\n",
    "    index_train=[]\n",
    "    \n",
    "    for label in unique_labels:\n",
    "        df_category=df_preprocessed_texts.loc[df_preprocessed_texts.labels == label]\n",
    "        number_of_recipes_in_category = df_category.labels.count()\n",
    "        index = df_category.index.values.tolist()\n",
    "        category_index_test = sample(index, int(number_of_recipes_in_category*split_ratio))\n",
    "        category_index_train = [i for i in index if i not in category_index_test]\n",
    "        index_test.extend(category_index_test)\n",
    "        index_train.extend(category_index_train)\n",
    "\n",
    "    print(index_test) #indecies of recipes in the validation dataset for each run of the crossvalidation\n",
    "    df_test = df_preprocessed_texts.loc[df_preprocessed_texts.index.isin(index_test)]\n",
    "    df_train = df_preprocessed_texts.loc[df_preprocessed_texts.index.isin(index_train)]\n",
    "    df_test.to_pickle(path_test_data)\n",
    "    df_train.to_pickle(path_train_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
